ttm:
  variant: "tiny"
  freeze_encoder: true
  unfreeze_last_n_blocks: 0
  lora: {enabled: false, r: 8, alpha: 16, dropout: 0.05}
head:
  kind: "mlp-classifier"   # or mlp-regressor/linear-*
  hidden_dims: [256, 128]
  dropout: 0.2
  out_dim: 2
